includes:
- configs/models/mmf_transformer/defaults.yaml

model_config:
  mmf_transformer:
    modalities:
    - type: text
      key: ocr
      segment_id: 0
    - type: image
      key: xray
      embedding_dim: 2048
      position_dim: 1
      segment_id: 1
    num_labels: 2
    losses:
    - type: cross_entropy

# Please see fbcode/faim/mmf/mmf/datasets/fb/builders/everstore/builder.py
# for details on configuration
dataset_config:
  everstore:
    constructor:
      namespace: ad_metrics
      table: political_ads_image_us_ssl_0609
      partitions: null
    set_name_key: set_name
    set_name_mapping:
      train: training
      val: validation
      test: testing
    schema:
    - fbid
    - xray
    - ocr
    - label
    - set_name
    everstore_col: everstore_handle
    filters: []
    processors:
      batch_processor:
        type: image_with_text
        params:
          feature_key: xray
          text_keys: ocr
          label_key: label
          id_key: fbid
          processors:
            text_processor:
              type: multi_sentence_bert_tokenizer
              params:
                tokenizer_config:
                  type: bert-base-uncased
                  params:
                    do_lower_case: true
                mask_probability: 0
                max_seq_length: 128
                fusion: stack
            feature_processor:
              type: xray_hash
              params: {}
            image_processor:
              type: torchvision_transforms
              params:
                transforms:
                  - type: Resize
                    params:
                      size: [256, 256]
                  - type: CenterCrop
                    params:
                      size: [224, 224]
                  - ToTensor
                  - GrayScaleTo3Channels
                  - type: Normalize
                    params:
                      mean: [0.46777044, 0.44531429, 0.40661017]
                      std: [0.12221994, 0.12145835, 0.14380469]

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 2000
    num_training_steps: ${training.max_updates}

optimizer:
  type: adam_w
  params:
    lr: 1e-5
    eps: 1e-8

evaluation:
    metrics:
    - binary_ap
    - roc_auc
    - type: r@pk
      key: r@p50
      params:
        p_threshold: 50
    - type: r@pk
      key: r@p90
      params:
        p_threshold: 90

training:
  batch_size: 32
  lr_scheduler: true
  max_updates: 22000
  early_stop:
    criteria: everstore/binary_ap
    minimize: false
