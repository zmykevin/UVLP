{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78591845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from iopath.common.file_io import PathManager as pm\n",
    "import json\n",
    "\n",
    "PathManager = pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcdae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(\"/home/zmykevin/fb_intern/data/mmf_data/datasets/flickr30k/defaults/annotations\", \"flickr30k_itm_train_final.jsonl\")\n",
    "data = []\n",
    "with open(train_data_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        d_point = json.loads(line)\n",
    "        data.append(d_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf6b0465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '1000092795.jpg', 'split': 'train', 'captions': ['Two young guys with shaggy hair look at their hands while hanging out in the yard.'], 'sentid': 0, 'label': 1}, {'filename': '1000092795.jpg', 'split': 'train', 'captions': ['Two young, White males are outside near many bushes.'], 'sentid': 1, 'label': 1}, {'filename': '1000092795.jpg', 'split': 'train', 'captions': ['Two men in green shirts are standing in a yard.'], 'sentid': 2, 'label': 1}, {'filename': '1000092795.jpg', 'split': 'train', 'captions': ['A man in a blue shirt standing in a garden.'], 'sentid': 3, 'label': 1}, {'filename': '1000092795.jpg', 'split': 'train', 'captions': ['Two friends enjoy time spent together.'], 'sentid': 4, 'label': 1}, {'filename': '10002456.jpg', 'split': 'train', 'captions': ['Several men in hard hats are operating a giant pulley system.'], 'sentid': 5, 'label': 1}, {'filename': '10002456.jpg', 'split': 'train', 'captions': ['Workers look down from up above on a piece of equipment.'], 'sentid': 6, 'label': 1}, {'filename': '10002456.jpg', 'split': 'train', 'captions': ['Two men working on a machine wearing hard hats.'], 'sentid': 7, 'label': 1}, {'filename': '10002456.jpg', 'split': 'train', 'captions': ['Four men on top of a tall structure.'], 'sentid': 8, 'label': 1}, {'filename': '10002456.jpg', 'split': 'train', 'captions': ['Three men on a large rig.'], 'sentid': 9, 'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1801bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'sentids': [0, 1, 2, 3, 4], 'imgid': 0, 'sentences': [{'tokens': ['two', 'young', 'guys', 'with', 'shaggy', 'hair', 'look', 'at', 'their', 'hands', 'while', 'hanging', 'out', 'in', 'the', 'yard'], 'raw': 'Two young guys with shaggy hair look at their hands while hanging out in the yard.', 'imgid': 0, 'sentid': 0}, {'tokens': ['two', 'young', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes'], 'raw': 'Two young, White males are outside near many bushes.', 'imgid': 0, 'sentid': 1}, {'tokens': ['two', 'men', 'in', 'green', 'shirts', 'are', 'standing', 'in', 'a', 'yard'], 'raw': 'Two men in green shirts are standing in a yard.', 'imgid': 0, 'sentid': 2}, {'tokens': ['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'in', 'a', 'garden'], 'raw': 'A man in a blue shirt standing in a garden.', 'imgid': 0, 'sentid': 3}, {'tokens': ['two', 'friends', 'enjoy', 'time', 'spent', 'together'], 'raw': 'Two friends enjoy time spent together.', 'imgid': 0, 'sentid': 4}], 'split': 'train', 'filename': '1000092795.jpg'}\n"
     ]
    }
   ],
   "source": [
    "#ann_data_path = \"/fsx/zmykevin/data/mmf_data/datasets/visual_entailment/defaults/annotations/snli_ve_test.jsonl\"\n",
    "data_path = \"/home/zmykevin/fb_intern/data/mmf_data/datasets/flickr30k/defaults/annotations\"\n",
    "#ann_data_path = \"/fsx/zmykevin/data/mmf_data/datasets/flickr30k/defaults/annotations/dataset_flickr30k.json\"\n",
    "ann_data_path = os.path.join(data_path, \"dataset_flickr30k.json\")\n",
    "with open(ann_data_path, \"r\") as f:\n",
    "    ann_data = json.load(f)\n",
    "print(type(ann_data))\n",
    "print(ann_data[\"images\"][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a69fd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'dataset'])\n"
     ]
    }
   ],
   "source": [
    "#Logics Training with pre-generate data\n",
    "import random\n",
    "\n",
    "print(ann_data.keys())\n",
    "flickr30k = {}\n",
    "for x in ann_data[\"images\"]:\n",
    "    current_split = x['split']\n",
    "    filename = x['filename']\n",
    "    if flickr30k.get(current_split, None) is None:\n",
    "        flickr30k[current_split] = []\n",
    "        \n",
    "    for sent in x[\"sentences\"]:\n",
    "        current_data_point = {}\n",
    "        current_data_point[\"filename\"] = filename\n",
    "        current_data_point[\"split\"] = current_split\n",
    "        current_data_point[\"captions\"] = [sent[\"raw\"]]\n",
    "        current_data_point[\"sentid\"] = sent[\"sentid\"]\n",
    "        current_data_point[\"label\"] = 1\n",
    "            #\n",
    "#         if current_split == \"val\":\n",
    "#             #By 50% chance, we will have a neg_caption\n",
    "#             if random.random() < 0.5:\n",
    "#                 neg_sample = random.choice(ann_data[\"images\"]) #Only Sample from Validation Images\n",
    "#                 while neg_sample[\"filename\"] == filename:\n",
    "#                     neg_sample = random.choice(ann_data[\"images\"])\n",
    "#                 neg_caption = random.choice(neg_sample[\"sentences\"])[\"raw\"]\n",
    "#                 current_data_point[\"neg_captions\"] = [neg_caption]\n",
    "#                 current_data_point[\"label\"] = 0\n",
    "#             else:\n",
    "#                 current_data_point[\"neg_captions\"] = []\n",
    "#                 current_data_point[\"label\"] = 1\n",
    "                \n",
    "        flickr30k[current_split].append(current_data_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508b4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145000\n",
      "5070\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(flickr30k[\"train\"]))\n",
    "print(len(flickr30k[\"val\"]))\n",
    "print(len(flickr30k[\"test\"]))\n",
    "\n",
    "\n",
    "flickr30k[\"minitest\"] = []\n",
    "for i,x in enumerate(flickr30k[\"train\"]):\n",
    "    flickr30k[\"minitest\"].append(x)\n",
    "#     if i == 999:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afccb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design Fixed Val\n",
    "old_val = flickr30k[\"val\"].copy()\n",
    "flickr30k[\"val\"] = []\n",
    "for x in old_val:\n",
    "    current_data_point = x.copy()\n",
    "    if random.random() < 0.5:\n",
    "        neg_sample = random.choice(old_val) #Only Sample from Validation Images\n",
    "        while neg_sample[\"filename\"] == filename:\n",
    "            neg_sample = random.choice(old_val)\n",
    "        neg_caption = neg_sample[\"captions\"][0]\n",
    "        current_data_point[\"neg_captions\"] = [neg_caption]\n",
    "        current_data_point[\"label\"] = 0\n",
    "    else:\n",
    "        current_data_point[\"neg_captions\"] = []\n",
    "    flickr30k[\"val\"].append(current_data_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d4eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '1018148011.jpg', 'split': 'val', 'captions': ['A group of people stand in the back of a truck filled with cotton.'], 'sentid': 335, 'label': 1, 'neg_captions': []}, {'filename': '1018148011.jpg', 'split': 'val', 'captions': ['Men are standing on and about a truck carrying a white substance.'], 'sentid': 336, 'label': 0, 'neg_captions': ['A black dog digs in the snow.']}, {'filename': '1018148011.jpg', 'split': 'val', 'captions': ['A group of people are standing on a pile of wool in a truck.'], 'sentid': 337, 'label': 1, 'neg_captions': []}, {'filename': '1018148011.jpg', 'split': 'val', 'captions': ['A group of men are loading cotton onto a truck'], 'sentid': 338, 'label': 0, 'neg_captions': ['A mounted policeman on a dappled horse surveys a crowd.']}, {'filename': '1018148011.jpg', 'split': 'val', 'captions': ['Workers load sheared wool onto a truck.'], 'sentid': 339, 'label': 0, 'neg_captions': ['A man has a pan and what looks like a block of dirt.']}, {'filename': '1029450589.jpg', 'split': 'val', 'captions': ['An adult wearing a gray shirt with red sleeves sleeping on a couch.'], 'sentid': 495, 'label': 1, 'neg_captions': []}, {'filename': '1029450589.jpg', 'split': 'val', 'captions': ['A woman in black pants napping on the couch.'], 'sentid': 496, 'label': 1, 'neg_captions': []}, {'filename': '1029450589.jpg', 'split': 'val', 'captions': ['A man sleeping in a green room on a couch.'], 'sentid': 497, 'label': 0, 'neg_captions': ['Two women, one in a blue uniform, the other in a white one, are competing in a martial arts match as a referee looks on.']}, {'filename': '1029450589.jpg', 'split': 'val', 'captions': ['The young woman is sleeping in her room.'], 'sentid': 498, 'label': 1, 'neg_captions': []}, {'filename': '1029450589.jpg', 'split': 'val', 'captions': ['A long-haired man sleeping on a couch'], 'sentid': 499, 'label': 1, 'neg_captions': []}]\n"
     ]
    }
   ],
   "source": [
    "print(flickr30k[\"val\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2324c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000\n"
     ]
    }
   ],
   "source": [
    "flickr30k[\"minitest_final\"] = []\n",
    "last_filename = \"\"\n",
    "for j in range(0, len(flickr30k[\"minitest\"]), 5):\n",
    "    #iterate through image\n",
    "    x = flickr30k[\"minitest\"][j]\n",
    "    for i,y in enumerate(flickr30k[\"minitest\"]):\n",
    "        new_x = x.copy()\n",
    "        assert new_x[\"filename\"] != last_filename\n",
    "#         new_x = x.copy()\n",
    "        new_x[\"captions\"] = y[\"captions\"].copy()\n",
    "        new_x[\"sample_id\"] = i\n",
    "        new_x[\"label\"] = int(y[\"filename\"] == new_x[\"filename\"])\n",
    "        flickr30k[\"minitest_final\"].append(new_x)\n",
    "    last_filename = new_x[\"filename\"]\n",
    "\n",
    "print(len(flickr30k[\"minitest_final\"]))\n",
    "#print(flickr30k[\"minitest_final\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217900e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = os.path.join(data_path, \"flickr30k_itm_val_final.jsonl\")\n",
    "with open(output_data_path, 'w') as outfile:\n",
    "    for entry in flickr30k[\"val\"]:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc19061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Feature\n",
    "class PaddedFasterRCNNFeatureReader:\n",
    "    def __init__(self, max_loc):\n",
    "        self.max_loc = max_loc\n",
    "        self.first = True\n",
    "        self.take_item = False\n",
    "\n",
    "    def _load(self, image_feat_path):\n",
    "        image_info = {}\n",
    "        image_info[\"features\"] = load_feat(image_feat_path)\n",
    "\n",
    "        info_path = \"{}_info.npy\".format(image_feat_path.split(\".npy\")[0])\n",
    "        if PathManager.exists(info_path):\n",
    "            image_info.update(load_feat(info_path).item())\n",
    "\n",
    "        return image_info\n",
    "\n",
    "    def read(self, image_feat_path):\n",
    "        image_info = self._load(image_feat_path)\n",
    "        if self.first:\n",
    "            self.first = False\n",
    "            if (\n",
    "                image_info[\"features\"].size == 1\n",
    "                and \"image_feat\" in image_info[\"features\"].item()\n",
    "            ):\n",
    "                self.take_item = True\n",
    "\n",
    "        image_feature = image_info[\"features\"]\n",
    "#         print(image_info[\"features\"].size)\n",
    "        if self.take_item:\n",
    "            item = image_info[\"features\"].item()\n",
    "            if \"image_text\" in item:\n",
    "                image_info[\"image_text\"] = item[\"image_text\"]\n",
    "                image_info[\"is_ocr\"] = item[\"image_bbox_source\"]\n",
    "                image_feature = item[\"image_feat\"]\n",
    "\n",
    "            if \"info\" in item:\n",
    "                if \"image_text\" in item[\"info\"]:\n",
    "                    image_info.update(item[\"info\"])\n",
    "                image_feature = item[\"feature\"]\n",
    "\n",
    "        # Handle case of features with class probs\n",
    "        if (\n",
    "            image_info[\"features\"].size == 1\n",
    "            and \"features\" in image_info[\"features\"].item()\n",
    "        ):\n",
    "            item = image_info[\"features\"].item()\n",
    "            image_feature = item[\"features\"]\n",
    "            image_info[\"image_height\"] = item[\"image_height\"]\n",
    "            image_info[\"image_width\"] = item[\"image_width\"]\n",
    "\n",
    "            # Resize these to self.max_loc\n",
    "            image_loc, _ = image_feature.shape\n",
    "            image_info[\"cls_prob\"] = np.zeros(\n",
    "                (self.max_loc, item[\"cls_prob\"].shape[1]), dtype=np.float32\n",
    "            )\n",
    "            image_info[\"cls_prob\"][0:image_loc,] = item[\"cls_prob\"][: self.max_loc, :]\n",
    "            image_info[\"bbox\"] = np.zeros(\n",
    "                (self.max_loc, item[\"bbox\"].shape[1]), dtype=np.float32\n",
    "            )\n",
    "            image_info[\"bbox\"][0:image_loc,] = item[\"bbox\"][: self.max_loc, :]\n",
    "            image_info[\"num_boxes\"] = item[\"num_boxes\"]\n",
    "\n",
    "        # Handle the case of ResNet152 features\n",
    "        if len(image_feature.shape) > 2:\n",
    "            shape = image_feature.shape\n",
    "            image_feature = image_feature.reshape(-1, shape[-1])\n",
    "\n",
    "        image_loc, image_dim = image_feature.shape\n",
    "        tmp_image_feat = np.zeros((self.max_loc, image_dim), dtype=np.float32)\n",
    "        tmp_image_feat[0:image_loc,] = image_feature[: self.max_loc, :]  # noqa\n",
    "        image_feature = torch.from_numpy(tmp_image_feat)\n",
    "\n",
    "        del image_info[\"features\"]\n",
    "        image_info[\"max_features\"] = torch.tensor(image_loc, dtype=torch.long)\n",
    "        return image_feature, image_info\n",
    "\n",
    "\n",
    "class LMDBFeatureReader(PaddedFasterRCNNFeatureReader):\n",
    "    def __init__(self, max_loc, base_path):\n",
    "        super().__init__(max_loc)\n",
    "        self.db_path = base_path\n",
    "\n",
    "        if not PathManager.exists(self.db_path):\n",
    "            raise RuntimeError(\n",
    "                \"{} path specified for LMDB features doesn't exists.\".format(\n",
    "                    self.db_path\n",
    "                )\n",
    "            )\n",
    "        self.env = None\n",
    "\n",
    "    def _init_db(self):\n",
    "        self.env = lmdb.open(\n",
    "            self.db_path,\n",
    "            subdir=os.path.isdir(self.db_path),\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "        )\n",
    "        with self.env.begin(write=False, buffers=True) as txn:\n",
    "            self.image_ids = pickle.loads(txn.get(b\"keys\"))\n",
    "            self.image_id_indices = {\n",
    "                self.image_ids[i]: i for i in range(0, len(self.image_ids))\n",
    "            }\n",
    "\n",
    "    def _load(self, image_file_path):\n",
    "        #print(\"env is: {}\".format(self.env))\n",
    "        if self.env is None:\n",
    "            #print(\"initialize db\")\n",
    "            self._init_db()\n",
    "\n",
    "        split = os.path.relpath(image_file_path, self.db_path).split(\".npy\")[0]\n",
    "\n",
    "        try:\n",
    "            image_id = int(split.split(\"_\")[-1])\n",
    "            # Try fetching to see if it actually exists otherwise fall back to\n",
    "            # default\n",
    "            img_id_idx = self.image_id_indices[str(image_id).encode()]\n",
    "        except (ValueError, KeyError):\n",
    "            # The image id is complex or involves folder, use it directly\n",
    "            image_id = str(split).encode()\n",
    "            img_id_idx = self.image_id_indices[image_id]\n",
    "\n",
    "        with self.env.begin(write=False, buffers=True) as txn:\n",
    "            image_info = pickle.loads(txn.get(self.image_ids[img_id_idx]))\n",
    "\n",
    "        return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784e82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/fsx/zmykevin/data/mmf_data/datasets/flickr30k/defaults/features/vinvl_detectron_sample.lmdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d570ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reader = LMDBFeatureReader(100, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a722ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, info = feature_reader.read(\"/fsx/zmykevin/data/mmf_data/datasets/vinvl_detectron_sample.lmdb/defaults/features/detectron.lmdb/flickr30k_1000092795.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6fe1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58895cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image_id', 'image_height', 'image_width', 'num_boxes', 'objects', 'bbox', 'cls_prob', 'max_features'])\n"
     ]
    }
   ],
   "source": [
    "print(info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66158008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000092795\n"
     ]
    }
   ],
   "source": [
    "print(info['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f5e5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(info['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bbffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
