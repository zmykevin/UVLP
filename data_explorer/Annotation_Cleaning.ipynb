{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc487ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c821080",
   "metadata": {},
   "source": [
    "## Reorgnizing the Dataset\n",
    " * Remove the String element from the Json file as much as we can\n",
    " * Remove the unnecessary elements from the Annotation Dataset\n",
    "\n",
    "### Masked Conceptual Captions\n",
    "* Remove \"objects\"\n",
    "\n",
    "### Masked Conceptual Captions Region Phrase\n",
    "* Remove objects\n",
    "* Convert objects_norep to use objects_ids\n",
    "* Remove list of noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Masked Conceptual Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f8f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_objects(input_prefix, output_prefix, base_path, train_index_list):\n",
    "    for index in train_index_list:\n",
    "        npy_path = os.path.join(base_path, \"{}_{}.npy\".format(input_prefix,index))\n",
    "        val_vinvl = np.load(npy_path, allow_pickle=True)\n",
    "        new_val_vinvl = []\n",
    "        for x in tqdm(val_vinvl):\n",
    "            new_x = x.copy()\n",
    "            new_x.pop(\"objects\")\n",
    "            new_val_vinvl.append(new_x)\n",
    "        with open(os.path.join(base_path, \"{}_{}.npy\".format(output_prefix, index)), \"wb\") as f:\n",
    "            print(\"{}_{}.npy\".format(output_prefix,index))\n",
    "            np.save(f, new_val_vinvl)\n",
    "    \n",
    "def pop_convert_objects(input_prefix, output_prefix, base_path, train_index_list):\n",
    "    for index in train_index_list:\n",
    "        npy_path = os.path.join(base_path, \"{}_{}.npy\".format(input_prefix,index))\n",
    "        val_vinvl = np.load(npy_path, allow_pickle=True)\n",
    "        #print(val_vinvl[0])\n",
    "        new_val_vinvl = []\n",
    "        for x in tqdm(val_vinvl):\n",
    "            new_x = x.copy()\n",
    "            objects=new_x.pop(\"objects\")\n",
    "            objects_norep = new_x.pop(\"objects_norep\")\n",
    "            objects_cs = np.zeros((len(objects),len(x[\"noun_phrases\"])))\n",
    "            objects_cs_arg = np.zeros((len(objects),len(x[\"noun_phrases\"])))\n",
    "            for i,ob in enumerate(objects):\n",
    "                for j in range(len(x[\"noun_phrases\"])):\n",
    "                    objects_cs[i][j] = objects_norep[ob][j][0]\n",
    "                    objects_cs_arg[i][j] = objects_norep[ob][j][1]\n",
    "            new_x[\"objects_cs\"] = objects_cs\n",
    "            new_x[\"objects_cs_arg\"] = objects_cs_arg\n",
    "            new_val_vinvl.append(new_x)\n",
    "\n",
    "        with open(os.path.join(base_path, \"{}_{}.npy\".format(output_prefix, index)), \"wb\") as f:\n",
    "            print(\"{}_{}.npy\".format(output_prefix,index))\n",
    "            np.save(f, new_val_vinvl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a8d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "base_path = \"/fsx/zmykevin/data/mmf_data/datasets/cc/defaults/annotations\"\n",
    "train_index_list = [0,1,2,3,6,7,8,9]\n",
    "\n",
    "#Load the object ids\n",
    "with open(os.path.join(base_path,\"cc_objects_id.json\"), \"r\") as f:\n",
    "    object_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d785d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258858/258858 [00:41<00:00, 6273.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_0.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258663/258663 [00:41<00:00, 6232.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258681/258681 [00:41<00:00, 6218.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 776072/776072 [02:25<00:00, 5345.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258373/258373 [00:42<00:00, 6115.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_6.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258380/258380 [00:42<00:00, 6135.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_7.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258457/258457 [00:43<00:00, 6010.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_8.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 572994/572994 [01:32<00:00, 6219.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vinvl_sbert_bc_nps_9.npy\n"
     ]
    }
   ],
   "source": [
    "input_prefix = \"train_vinvl_sbert_bc_nps_fixed\"\n",
    "output_prefix = \"train_vinvl_sbert_bc_nps\"\n",
    "\n",
    "\n",
    "for index in train_index_list:\n",
    "    npy_path = os.path.join(base_path, \"{}_{}.npy\".format(input_prefix,index))\n",
    "    val_vinvl = np.load(npy_path, allow_pickle=True)\n",
    "    #print(val_vinvl[0])\n",
    "    new_val_vinvl = []\n",
    "    for x in tqdm(val_vinvl):\n",
    "        new_x = x.copy()\n",
    "        objects=new_x.pop(\"objects\")\n",
    "        objects_norep = new_x.pop(\"objects_norep\")\n",
    "        objects_cs = np.zeros((len(objects),len(x[\"noun_phrases\"])))\n",
    "        objects_cs_arg = np.zeros((len(objects),len(x[\"noun_phrases\"])))\n",
    "        for i,ob in enumerate(objects):\n",
    "            for j in range(len(x[\"noun_phrases\"])):\n",
    "                objects_cs[i][j] = objects_norep[ob][j][0]\n",
    "                objects_cs_arg[i][j] = objects_norep[ob][j][1]\n",
    "        \n",
    "        new_x[\"objects_cs\"] = objects_cs\n",
    "        new_x[\"objects_cs_arg\"] = objects_cs_arg\n",
    "        new_x[\"objects_ids\"] = [object_ids[x] for x in objects]\n",
    "        new_val_vinvl.append(new_x)\n",
    "#         break\n",
    "#     print(new_val_vinvl)\n",
    "#     break\n",
    "        \n",
    "    #print(new_val_vinvl)\n",
    "    \n",
    "    with open(os.path.join(base_path, \"{}_{}.npy\".format(output_prefix, index)), \"wb\") as f:\n",
    "        print(\"{}_{}.npy\".format(output_prefix,index))\n",
    "        np.save(f, new_val_vinvl)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2532bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write out to train_vinvl_sbert_retrieved_sorted_all_nps_cs_mini_fixed.npy\n"
     ]
    }
   ],
   "source": [
    "#Save a miniset for debugging\n",
    "# output_path = os.path.join(base_path, \"train_vinvl_sbert_retrieved_sorted_all_nps_cs_mini_fixed.npy\")\n",
    "# with open(output_path, \"wb\") as f:\n",
    "#     print(\"write out to {}\".format(output_path.split(\"/\")[-1]))\n",
    "#     np.save(f, new_val_vinvl[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313361ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mmf)",
   "language": "python",
   "name": "mmf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
